# ðŸ¤– RAG MultiLLM

## ðŸ“ DescripciÃ³n
RAG MultiLLM es un sistema de RecuperaciÃ³n Aumentada de GeneraciÃ³n (RAG) que integra mÃºltiples modelos de lenguajen. Esta aplicaciÃ³n permite interactuar con tres de los LLMs mÃ¡s potentes del mercado: Claude 3.5 Sonnet de Anthropic, GPT-4 Turbo de OpenAI y Mistral Large de Mistral AI. El sistema estÃ¡ diseÃ±ado para proporcionar respuestas contextualizadas y precisas basadas en documentos PDF proporcionados por el usuario.

## âœ¨ CaracterÃ­sticas Principales
- **ðŸ”„ MÃºltiples Modelos**: IntegraciÃ³n con tres LLMs lÃ­deres:
  - ðŸ§  claude-3-5-sonnet-latest (Anthropic)
  - ðŸŒŸ chatgpt-4o Turbo (OpenAI)
  - âš¡ Mistral Large (Mistral AI)
- **ðŸ“š Sistema RAG Avanzado**: Procesamiento y recuperaciÃ³n inteligente de informaciÃ³n desde documentos PDF
- **ðŸŽ¨ Interfaz Moderna**: UI/UX intuitiva con Material Design
- **ðŸ“‹ Respuestas Estructuradas**: Formato HTML enriquecido con referencias y citas
- **âš¡ Procesamiento AsÃ­ncrono**: Manejo eficiente de solicitudes y respuestas

## ðŸ“‹ Requisitos Previos
- ðŸ Python 3.10 o superior
- ðŸ“¦ pip (gestor de paquetes de Python)
- ðŸ”‘ Claves API de:
  - Anthropic (Claude)
  - OpenAI (GPT-4o)
  - Mistral AI

## ðŸš€ InstalaciÃ³n

1. Clonar el repositorio:
```bash
git clone https://github.com/yourusername/rag-multillm.git
cd rag-multillm
```

2. Crear y activar entorno virtual:
```bash
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. Instalar dependencias:
```bash
pip install -r requirements.txt
```

## âš™ï¸ ConfiguraciÃ³n
Crear un archivo `.env` en la raÃ­z del proyecto:
```env
ANTHROPIC_API_KEY=your_anthropic_api_key
OPENAI_API_KEY=your_openai_api_key
MISTRAL_API_KEY=your_mistral_api_key
FLASK_SECRET_KEY=your_flask_secret_key
```

## ðŸ“¦ Dependencias Principales
```text
flask==3.0.2
python-dotenv==1.0.1
langchain==0.1.9
langchain-community==0.0.24
langchain-anthropic==0.1.1
langchain-openai==0.0.8
langchain-mistralai==0.0.3
anthropic==0.18.1
openai==1.12.0
mistralai>=0.0.11,<0.0.12
faiss-cpu==1.7.4
sentence-transformers==2.5.1
pypdf==4.1.0
```

## ðŸŽ® Uso
1. Iniciar la aplicaciÃ³n:
```bash
python app.py
```

2. Abrir el navegador y acceder a:
```
http://localhost:5000
```

3. Seleccionar el modelo de IA deseado
4. Realizar preguntas sobre los documentos cargados

## ðŸ“ Estructura del Proyecto
```
rag-multillm/
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”œâ”€â”€ js/
â”‚   â””â”€â”€ images/
â”œâ”€â”€ templates/
â”œâ”€â”€ documentos/
â”œâ”€â”€ .env
â”œâ”€â”€ app.py
â”œâ”€â”€ config.py
â”œâ”€â”€ rag.py
â””â”€â”€ requirements.txt
```

## ðŸ¤– CaracterÃ­sticas de los Modelos

### ðŸ§  Claude 3.5 Sonnet
- Excelente comprensiÃ³n contextual
- Respuestas detalladas y estructuradas
- Soporte multilingÃ¼e avanzado

### ðŸŒŸ GPT-4 Turbo
- Alta precisiÃ³n en respuestas
- Razonamiento complejo
- Versatilidad en tareas diversas

### âš¡ Mistral Large
- Alto rendimiento y velocidad
- Excelente en anÃ¡lisis tÃ©cnico
- Eficiente en recursos

## ðŸ¤ ContribuciÃ³n
Las contribuciones son bienvenidas. Por favor, sigue estos pasos:
1. Fork el repositorio
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Crea un Pull Request

## ðŸ“„ Licencia
Este proyecto estÃ¡ bajo la licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ðŸ‘¨â€ðŸ’» Autor
@686f6c61

## ðŸ”– VersiÃ³n
v0.3 - IntegraciÃ³n de mÃºltiples modelos LLM
